{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading necessary libraries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import scipy.stats as stat\n",
    "import pylab\n",
    "from sklearn.preprocessing import LabelEncoder,OneHotEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score,classification_report,confusion_matrix\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic EDA\n",
    "def EDA(data_frame):\n",
    "    print('The 1st 5 columns are:\\n',data_frame.head())\n",
    "    print('****************************\\n')\n",
    "    print('The shape of the dataset is:\\n',data_frame.shape)\n",
    "    print('****************************\\n')\n",
    "    print('The information of the dataset is:\\n',data_frame.info())\n",
    "    print('****************************\\n')\n",
    "    print('The description of the dataset is:\\n',data_frame.describe())\n",
    "    print('The description of the dataset is:\\n',data_frame.describe(include='O'))\n",
    "    print('****************************\\n')\n",
    "    print('The number of null values is:\\n',data_frame.isnull().sum())\n",
    "    print('****************************\\n')\n",
    "    print('The percentage of null values is:\\n',data_frame.isnull().mean())\n",
    "    print('****************************\\n')\n",
    "    print('The number of duplicated rows in the dataset are:\\n',data_frame.duplicated().sum())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for removing duplicated rows\n",
    "def remove_duplicates(data_frame):\n",
    "    new_df=data_frame.drop_duplicates()\n",
    "    new_df.reset_index(drop=True)\n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for separating numerical and categorical values\n",
    "\n",
    "def separate_numcat_feature(data_frame):\n",
    "    numerical_features=[feature for feature in data_frame.columns if data_frame[feature].dtype!='O']\n",
    "    categorical_features=[feature for feature in data_frame.columns if feature not in numerical_features]\n",
    "    return numerical_features,categorical_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipeline for handling null values\n",
    "numeric_processor=Pipeline(steps=[(\"imputation_median\",SimpleImputer(missing_values=np.nan,strategy=\"median\"))])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for detecting and handling null values\n",
    "\n",
    "def handlingOutliers(new_df):\n",
    "    for feature in numerical_features:\n",
    "        Q1=new_df[feature].quantile(0.25)\n",
    "        Q3=new_df[feature].quantile(0.75)\n",
    "        IQR=Q3-Q1\n",
    "        lowerLimit=Q1-(1.5*IQR)\n",
    "        upperLimit=Q3+(1.5*IQR)\n",
    "        new_df.loc[(new_df[feature]<lowerLimit),feature]=lowerLimit\n",
    "        new_df.loc[(new_df[feature]>upperLimit),feature]=upperLimit\n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for transformation\n",
    "def transform(new_df):\n",
    "    for feature in numerical_features:\n",
    "        new_df[feature],transval=stat.boxcox(new_df[feature])\n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function for categorical encoding\n",
    "def categoricalEncoding(data_frame,feature,method):\n",
    "    if method=='oneHotEncoding':\n",
    "        data_frameNew=pd.get_dummies(data_frame,columns=[feature],dtype=int)\n",
    "    elif method=='LabelEncoder':\n",
    "        encoder=LabelEncoder()\n",
    "        data_frame[feature]=encoder.fit_transform(data_frame[feature])\n",
    "        data_frameNew=data_frame\n",
    "        \n",
    "    return data_frameNew\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipelineLr=Pipeline(steps=[(\"scaler1\",MinMaxScaler()),(\"Lr_clf\",LogisticRegression(multi_class='multinomial'))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeLineDt=Pipeline(steps=[(\"scaler2\",MinMaxScaler()),(\"DT_clf\",DecisionTreeClassifier())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import set_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipelineRnn=Pipeline(steps=[(\"scaler3\",MinMaxScaler()),(\"Rnn_clf\",RandomForestClassifier(n_estimators=100))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeLineSvc=Pipeline(steps=[(\"scaler4\",MinMaxScaler),(\"svc_clf\",SVC(kernel=\"rbf\"))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline=[pipelineLr,pipeLineDt,pipelineRnn,pipeLineSvc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for pipe in pipeline:\n",
    "    pipe.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_accuracy =0.0\n",
    "best_classifier=0\n",
    "best_pipeline=\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in enumerate(pipeline):\n",
    "    print(f\"test accuracy for {model}: {model.score(X_test,Y_test)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip_dict={\"0\":\"LogisticRegression\",\"1\":\"DecisiontreeClassifier\",\"2\":\"RandomForestClassifier\",\"3\":\"SupportvectorClassifier\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,model in enumerate(pipeline):\n",
    "    if model.score(X_test,Y_test) > best_accuracy:\n",
    "        best_accuracy=model.score(X_test,Y_test)\n",
    "        best_pipeline=model\n",
    "        best_classifier=i\n",
    "print(f\"classifier with best accuracy is {pip_dict[best_classifier]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
